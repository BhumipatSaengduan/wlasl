# ü§ü WLASL Demo ‚Äî ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏à‡∏ô‡∏à‡∏ö

> ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡πà‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏∑‡∏≠ ASL ‚Üí ‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏•‡∏¢

---

## üìã ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

```
STEP 1  ‚Äî ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (Python, Node.js, ffmpeg, Git)
STEP 2  ‚Äî Clone repo
STEP 3  ‚Äî Train ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Google Colab
STEP 4  ‚Äî Fix labels + Export weights
STEP 5  ‚Äî Download weights ‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
STEP 6  ‚Äî ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
STEP 7  ‚Äî ‡∏£‡∏±‡∏ô Backend API
STEP 8  ‚Äî ‡∏£‡∏±‡∏ô Frontend (Web UI)
STEP 9  ‚Äî ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ú‡∏•
```

---

## STEP 1 ‚Äî ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

### 1.1 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python 3.10+
- ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î: https://www.python.org/downloads/
- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: `python --version` ‚Üí ‡πÄ‡∏´‡πá‡∏ô `Python 3.10.x`

### 1.2 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Node.js 18+
- ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î: https://nodejs.org
- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: `node --version` ‚Üí ‡πÄ‡∏´‡πá‡∏ô `v18.x.x`

### 1.3 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Git
- ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î: https://git-scm.com
- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: `git --version`

### 1.4 ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ffmpeg (Windows)

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 ‚Äî ‡∏ú‡πà‡∏≤‡∏ô winget (‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î):**
```powershell
winget install ffmpeg
```
‡∏õ‡∏¥‡∏î terminal ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô `ffmpeg -version`

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 ‚Äî ‡∏ñ‡πâ‡∏≤ winget ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:**
1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î: https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-gpl.zip
2. ‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå ‚Üí ‡∏¢‡πâ‡∏≤‡∏¢‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏õ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà `C:\ffmpeg`
3. ‡∏Å‡∏î **Windows key** ‚Üí ‡∏û‡∏¥‡∏°‡∏û‡πå `environment` ‚Üí **Edit the system environment variables**
4. ‡∏Ñ‡∏•‡∏¥‡∏Å **Environment Variables** ‚Üí ‡πÉ‡∏ô **User variables** ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å **Path** ‚Üí **Edit**
5. ‡∏Ñ‡∏•‡∏¥‡∏Å **New** ‚Üí ‡∏û‡∏¥‡∏°‡∏û‡πå `C:\ffmpeg\bin` ‚Üí **OK** ‡∏™‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡πâ‡∏á
6. ‡∏õ‡∏¥‡∏î VSCode ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡∏°‡πà
7. ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: `ffmpeg -version`

---

## STEP 2 ‚Äî Clone repo

‡πÄ‡∏õ‡∏¥‡∏î PowerShell ‡πÉ‡∏ô VSCode ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô:

```powershell
git clone https://github.com/BhumipatSaengduan/wlasl.git
cd wlasl
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `src/`, `scripts/`, `web/`, `colab/`

---

## STEP 3 ‚Äî Train ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Google Colab

### 3.1 ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° kaggle.json

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://www.kaggle.com/settings
2. ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏´‡∏≤ **API** ‚Üí ‡∏Ñ‡∏•‡∏¥‡∏Å **Create New Token**
3. ‡πÑ‡∏ü‡∏•‡πå `kaggle.json` ‡∏à‡∏∞ download ‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
4. ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ ‚Äî ‡πÉ‡∏ä‡πâ upload ‡πÄ‡∏Ç‡πâ‡∏≤ Colab ‡πÉ‡∏ô STEP 3.4

> ‚ö†Ô∏è ‡∏≠‡∏¢‡πà‡∏≤ push kaggle.json ‡∏Ç‡∏∂‡πâ‡∏ô GitHub ‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î

### 3.2 ‡πÄ‡∏õ‡∏¥‡∏î Notebook ‡πÉ‡∏ô Google Colab

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://colab.research.google.com
2. ‡∏Ñ‡∏•‡∏¥‡∏Å **File ‚Üí Upload notebook**
3. Upload ‡πÑ‡∏ü‡∏•‡πå `colab/Step7_Colab_Train_Export.ipynb` ‡∏à‡∏≤‡∏Å repo

### 3.3 ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Runtime ‡πÄ‡∏õ‡πá‡∏ô GPU

1. ‡∏Ñ‡∏•‡∏¥‡∏Å **Runtime** ‚Üí **Change runtime type**
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å **T4 GPU** ‚Üí **Save**

### 3.4 ‡∏£‡∏±‡∏ô Cell 1 ‚Äî Clone repo

```python
!git clone https://github.com/BhumipatSaengduan/wlasl.git
%cd wlasl
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô `Cloning into 'wlasl'...`

### 3.5 ‡∏£‡∏±‡∏ô Cell 2 ‚Äî ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies

```python
!pip -q install torch torchvision opencv-python tqdm
```

### 3.6 ‡∏£‡∏±‡∏ô Cell 3 ‚Äî Upload kaggle.json ‡πÅ‡∏•‡∏∞ download dataset

```python
!pip -q install kaggle
from google.colab import files
files.upload()  # popup ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå kaggle.json ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
!mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d risangbaskoro/wlasl-processed -p /content/data --unzip
!ls -la /content/data
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ:
```
videos/                ‚Üê ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (~11,980 ‡πÑ‡∏ü‡∏•‡πå)
nslt_100.json
WLASL_v0.3.json
wlasl_class_list.txt
```

‚è±Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: ~5-10 ‡∏ô‡∏≤‡∏ó‡∏µ

### 3.7 ‡∏£‡∏±‡∏ô Cell 4 ‚Äî Train ‡πÇ‡∏°‡πÄ‡∏î‡∏•

> ‚ö†Ô∏è ‡πÉ‡∏ä‡πâ code ‡∏ô‡∏µ‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ‡∏≠‡πà‡∏≤‡∏ô dataset ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)

‡πÄ‡∏û‡∏¥‡πà‡∏° cell ‡πÉ‡∏´‡∏°‡πà ‡∏ß‡∏≤‡∏á code ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô:

```python
import os, json, math
import numpy as np
import cv2
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
from tqdm import tqdm

os.chdir('/content/wlasl')  # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°

# --- Load dataset ‡∏à‡∏≤‡∏Å nslt_100.json ---
def load_nslt_dataset(data_root, json_path, max_classes=100, max_samples_per_class=50):
    with open(json_path) as f:
        data = json.load(f)
    video_dir = os.path.join(data_root, 'videos')
    class_to_samples = {}
    for video_id, info in data.items():
        class_idx = info['action'][0]
        video_file = os.path.join(video_dir, f"{int(video_id):05d}.mp4")
        if not os.path.exists(video_file):
            continue
        class_to_samples.setdefault(class_idx, []).append({
            'path': video_file, 'subset': info['subset']
        })
    selected_classes = sorted(class_to_samples.keys())[:max_classes]
    label_map = {orig: new for new, orig in enumerate(selected_classes)}
    train_samples, val_samples = [], []
    for orig_class in selected_classes:
        items = class_to_samples[orig_class][:max_samples_per_class]
        new_label = label_map[orig_class]
        for item in items:
            sample = (item['path'], new_label)
            if item['subset'] == 'val':
                val_samples.append(sample)
            else:
                train_samples.append(sample)
    labels = [str(c) for c in selected_classes]
    print(f"dataset: train={len(train_samples)} val={len(val_samples)} classes={len(selected_classes)}")
    return train_samples, val_samples, labels

# --- Model ---
class TinyFrameCNN(nn.Module):
    def __init__(self, in_ch=3, feat_dim=128):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, 32, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),
            nn.Conv2d(64, feat_dim, 3, padding=1), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),
        )
    def forward(self, x):
        return self.net(x).flatten(1)

class TinyVideoClassifier(nn.Module):
    def __init__(self, num_classes, frames=8, size=112, feat_dim=128):
        super().__init__()
        self.backbone = TinyFrameCNN(feat_dim=feat_dim)
        self.classifier = nn.Linear(feat_dim, num_classes)
    def forward(self, x):
        b, t, c, h, w = x.shape
        feat = self.backbone(x.view(b*t, c, h, w)).view(b, t, -1).mean(1)
        return self.classifier(feat)

# --- Dataset ---
FRAMES, SIZE = 8, 112

def sample_frames(path, num_frames=FRAMES, size=SIZE):
    cap = cv2.VideoCapture(path)
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frames = []
    if total > 0:
        for idx in np.linspace(0, total-1, num_frames, dtype=int):
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))
            ok, frame = cap.read()
            if ok and frame is not None:
                frame = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (size, size))
                frames.append(frame.astype(np.float32) / 255.0)
    cap.release()
    if not frames:
        frames = [np.zeros((size, size, 3), np.float32)]
    while len(frames) < num_frames:
        frames.append(frames[-1])
    arr = np.stack(frames[:num_frames])
    return torch.from_numpy(arr.transpose(0, 3, 1, 2)).float()

class VideoDataset(Dataset):
    def __init__(self, samples):
        self.samples = samples
    def __len__(self):
        return len(self.samples)
    def __getitem__(self, idx):
        path, label = self.samples[idx]
        return sample_frames(path), label

# --- Train ---
EPOCHS = 10
BATCH_SIZE = 8
LR = 1e-3
OUT_DIR = '/content/out'
os.makedirs(OUT_DIR, exist_ok=True)

train_samples, val_samples, labels = load_nslt_dataset(
    '/content/data', '/content/data/nslt_100.json',
    max_classes=100, max_samples_per_class=50
)

with open(f'{OUT_DIR}/labels.json', 'w') as f:
    json.dump(labels, f)

train_loader = DataLoader(VideoDataset(train_samples), batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader   = DataLoader(VideoDataset(val_samples),   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"device: {device}")

model = TinyVideoClassifier(num_classes=len(labels)).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=LR)
criterion = nn.CrossEntropyLoss()

best_loss = math.inf
for epoch in range(1, EPOCHS+1):
    model.train()
    train_loss = 0.0
    for x, y in tqdm(train_loader, desc=f"train {epoch}"):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        loss = criterion(model(x), y)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * x.size(0)
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for x, y in tqdm(val_loader, desc=f"val {epoch}"):
            x, y = x.to(device), y.to(device)
            val_loss += criterion(model(x), y).item() * x.size(0)
    train_loss /= max(1, len(train_samples))
    val_loss   /= max(1, len(val_samples))
    print(f"epoch={epoch} train_loss={train_loss:.4f} val_loss={val_loss:.4f}")
    if val_loss < best_loss:
        best_loss = val_loss
        torch.save({
            'state_dict': model.state_dict(),
            'meta': {'num_classes': len(labels), 'frames': FRAMES, 'size': SIZE}
        }, f'{OUT_DIR}/best.pt')
        print(f"  saved best checkpoint")
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô `classes=100` ‡πÅ‡∏•‡∏∞ loss ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 0
‚è±Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: ~20-40 ‡∏ô‡∏≤‡∏ó‡∏µ (GPU T4)

---

## STEP 4 ‚Äî Fix labels + Export weights (‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Colab)

### 4.1 ‡πÅ‡∏Å‡πâ labels.json ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏à‡∏£‡∏¥‡∏á

‡πÄ‡∏û‡∏¥‡πà‡∏° cell ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô:

```python
import json

# map index ‚Üí ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
class_list = {}
with open('/content/data/wlasl_class_list.txt') as f:
    for line in f:
        parts = line.strip().split('\t')
        if len(parts) >= 2:
            class_list[int(parts[0])] = parts[1]

# ‡πÇ‡∏´‡∏•‡∏î labels ‡πÄ‡∏î‡∏¥‡∏° (‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
with open('/content/out/labels.json') as f:
    old_labels = json.load(f)

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥
new_labels = [class_list.get(int(l), f"unknown_{l}") for l in old_labels]
print("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:", new_labels[:10])
print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(new_labels)} ‡∏Ñ‡∏≥")

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏±‡∏ö
with open('/content/out/labels.json', 'w') as f:
    json.dump(new_labels, f)
print("‚úÖ labels.json ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÅ‡∏•‡πâ‡∏ß")
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÄ‡∏ä‡πà‡∏ô `['book', 'drink', 'computer', ...]`

### 4.2 Export ‡πÄ‡∏õ‡πá‡∏ô TorchScript

‡πÄ‡∏û‡∏¥‡πà‡∏° cell ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô:

```python
import os
os.chdir('/content/wlasl')

!python3 -m src.export_torchscript \
    --ckpt /content/out/best.pt \
    --labels /content/out/labels.json \
    --out_ts /content/out/model.ts
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô
```
TorchScript output shape: (1, 100)
Saved TorchScript: /content/out/model.ts
```

### 4.3 Download ‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

‡πÄ‡∏û‡∏¥‡πà‡∏° cell ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô:

```python
from google.colab import files
files.download("/content/out/model.ts")
files.download("/content/out/labels.json")
```

Browser ‡∏à‡∏∞ download 2 ‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Downloads

---

## STEP 5 ‚Äî ‡∏ß‡∏≤‡∏á weights ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

‡πÄ‡∏õ‡∏¥‡∏î PowerShell ‡πÉ‡∏ô VSCode:

```powershell
cd "C:\Users\bhumi\Desktop\CMU\4th Year\Chalarm\WLASL\wlasl_demo"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå weights
mkdir -Force weights

# ‡∏ß‡∏≤‡∏á 2 ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà download ‡∏°‡∏≤
copy "$env:USERPROFILE\Downloads\model.ts" weights\
copy "$env:USERPROFILE\Downloads\labels.json" weights\
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:
```powershell
dir weights\
# ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô: labels.json  model.ts
```

---

## STEP 6 ‚Äî ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

```powershell
cd "C:\Users\bhumi\Desktop\CMU\4th Year\Chalarm\WLASL\wlasl_demo"
python -m venv .venv
.venv\Scripts\activate
pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
pip install opencv-python numpy fastapi uvicorn python-multipart tqdm rich
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:
```powershell
python scripts/healthcheck.py
```

‡∏Ñ‡∏ß‡∏£‡πÑ‡∏î‡πâ:
```
ffmpeg: OK
opencv: True
torch: True
OK: healthcheck passed
```

> ‡∏ñ‡πâ‡∏≤ ffmpeg: MISSING ‚Üí ‡∏î‡∏π STEP 1.4

---

## STEP 7 ‚Äî ‡∏£‡∏±‡∏ô Backend API

‡πÄ‡∏õ‡∏¥‡∏î **Terminal ‡∏ó‡∏µ‡πà 1** (‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏•‡∏≠‡∏î ‡∏´‡πâ‡∏≤‡∏°‡∏õ‡∏¥‡∏î):

```powershell
cd "C:\Users\bhumi\Desktop\CMU\4th Year\Chalarm\WLASL\wlasl_demo"
.venv\Scripts\activate
python -m uvicorn src.server:app --host 127.0.0.1 --port 8000
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô
```
Uvicorn running on http://127.0.0.1:8000
```

---

## STEP 8 ‚Äî ‡∏£‡∏±‡∏ô Frontend (Web UI)

‡πÄ‡∏õ‡∏¥‡∏î **Terminal ‡∏ó‡∏µ‡πà 2** (‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏•‡∏≠‡∏î ‡∏´‡πâ‡∏≤‡∏°‡∏õ‡∏¥‡∏î):

```powershell
cd "C:\Users\bhumi\Desktop\CMU\4th Year\Chalarm\WLASL\wlasl_demo\web"
npm install
npm run dev -- --hostname 127.0.0.1 --port 3000
```

‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: ‡πÄ‡∏´‡πá‡∏ô
```
‚ñ≤ Next.js 14.2.5
- Local: http://127.0.0.1:3000
‚úì Ready in 2.1s
```

---

## STEP 9 ‚Äî ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ú‡∏•

### 9.1 ‡πÄ‡∏õ‡∏¥‡∏î Browser

‡πÑ‡∏õ‡∏ó‡∏µ‡πà: **http://127.0.0.1:3000**

‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö **API: OK** ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß ‡∏°‡∏∏‡∏°‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤

### 9.2 ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

1. **‡∏õ‡∏•‡∏î checkbox Mock** ‡∏≠‡∏≠‡∏Å (untick)
2. ‡∏Ñ‡∏•‡∏¥‡∏Å **Advanced** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:
   - Weights path: `weights/model.ts`
   - Labels path: `weights/labels.json`

### 9.3 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Upload ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠

1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏∑‡∏≠ ASL (.mp4 ‡∏´‡∏£‡∏∑‡∏≠ .webm ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
2. ‡∏Ñ‡∏•‡∏¥‡∏Å **Choose file** ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
3. ‡∏Ñ‡∏•‡∏¥‡∏Å **Upload & Infer**
4. ‡∏î‡∏π‡∏ú‡∏•‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‚Äî ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏û‡∏£‡πâ‡∏≠‡∏° % confidence:

```
| Rank | Label    | Score |
|------|----------|-------|
|  1   | hello    | 45.2% |
|  2   | book     | 23.1% |
|  3   | drink    | 12.8% |
|  4   | help     |  9.4% |
|  5   | computer |  6.1% |
```

### 9.4 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô Webcam

1. ‡∏Å‡∏î **Start Recording**
2. ‡∏ó‡∏≥‡∏ó‡πà‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏∑‡∏≠ 1 ‡∏ó‡πà‡∏≤ (1 ‡∏Ñ‡∏≥) ‡∏ï‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á
3. ‡∏Å‡∏î **Stop Recording**
4. ‡∏£‡∏≠‡∏ú‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©

---

## ‚ùó Troubleshooting

| ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ | ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ | ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ |
|---|---|---|
| Label ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (32, 12...) | ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ fix labels | ‡∏ó‡∏≥ STEP 4.1 ‡πÅ‡∏•‡πâ‡∏ß download labels.json ‡πÉ‡∏´‡∏°‡πà |
| `status=unknown low_confidence` | score ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 50% | ‡∏õ‡∏Å‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å ‡∏•‡∏≠‡∏á train ‡πÄ‡∏û‡∏¥‡πà‡∏° epoch |
| `API: DOWN` | server ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô | ‡∏£‡∏±‡∏ô uvicorn ‡πÉ‡∏ô Terminal 1 |
| `WEIGHTS_MISSING` | ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô weights/ | ‡∏ó‡∏≥ STEP 5 |
| score ‡∏ó‡∏∏‡∏Å‡∏≠‡∏±‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô | Mock ‡∏¢‡∏±‡∏á‡∏ï‡∏¥‡πä‡∏Å‡∏≠‡∏¢‡∏π‡πà | ‡∏õ‡∏•‡∏î Mock ‡∏≠‡∏≠‡∏Å |
| `No module named 'src'` | ‡∏•‡∏∑‡∏° cd ‡πÄ‡∏Ç‡πâ‡∏≤ repo ‡πÉ‡∏ô Colab | ‡πÄ‡∏û‡∏¥‡πà‡∏° `os.chdir('/content/wlasl')` |
| `classes=1` ‡∏ï‡∏≠‡∏ô train | ‡∏≠‡πà‡∏≤‡∏ô dataset ‡∏ú‡∏¥‡∏î | ‡πÉ‡∏ä‡πâ code ‡πÉ‡∏ô STEP 3.7 ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÅ‡∏•‡πâ‡∏ß |
| Webcam ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô | browser block camera | ‡∏Å‡∏î Allow ‡πÄ‡∏°‡∏∑‡πà‡∏≠ browser ‡∏ñ‡∏≤‡∏°‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå |
| Colab session ‡∏´‡∏°‡∏î | ‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô | ‡∏£‡∏±‡∏ô Cell 4 ‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô |
| ffmpeg: MISSING | ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á | ‡∏ó‡∏≥ STEP 1.4 |

---

## üìä Checklist ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏à‡∏ô‡∏à‡∏ö

```
‚¨ú STEP 1  ‚Äî ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python, Node.js, Git, ffmpeg
‚¨ú STEP 2  ‚Äî Clone repo
‚¨ú STEP 3  ‚Äî Train ‡πÉ‡∏ô Colab (Cell 1-4)
‚¨ú STEP 4  ‚Äî Fix labels + Export model.ts
‚¨ú STEP 5  ‚Äî ‡∏ß‡∏≤‡∏á weights/ ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
‚¨ú STEP 6  ‚Äî ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python packages
‚¨ú STEP 7  ‚Äî ‡∏£‡∏±‡∏ô server (Terminal 1)
‚¨ú STEP 8  ‚Äî ‡∏£‡∏±‡∏ô web (Terminal 2)
‚¨ú STEP 9  ‚Äî ‡πÄ‡∏õ‡∏¥‡∏î http://127.0.0.1:3000 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Real mode
```
